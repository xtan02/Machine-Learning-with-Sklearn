{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>***机器学习模型1：SVM & Decisition tree***</center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_reg = pd.read_csv(\"data\\\\boston_house_prices.csv\", header=1)\n",
    "df_cls = pd.read_csv(\"data\\\\iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_reg.drop(\"MEDV\", axis=1)    # 选择特征空间X\n",
    "y1 = df_reg.MEDV    # 选择标签y\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)     # 划分数据集\n",
    "\n",
    "X2 = df_cls.drop(\"virginica\", axis=1)\n",
    "y2 = df_cls['virginica']\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***支持向量机***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **线性支持向量机（Linear SVM）：**\n",
    "\n",
    " 这是最基本的SVM类型，用于解决线性可分问题。它通过找到一个超平面（在二维空间中就是一条直线，多维空间中是一个超平面），将不同类别的样本分开，并且使得两侧离超平面最近的样本点的距离最大化。这些最近的样本点被称为支持向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 线性支持向量机（分类）\n",
    "linear_svm = svm.SVC(kernel='linear')   # 模型初始化\n",
    "linear_svm.fit(X2_train, y2_train)    # 模型拟合\n",
    "linear_predictions = linear_svm.predict(X2_test)    # 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **非线性支持向量机（Non-linear SVM）：**\n",
    "\n",
    " 当数据在特征空间中不是线性可分时，就需要使用非线性SVM。这可以通过将数据映射到高维空间，使其在新空间中线性可分，或者使用核函数（Kernel Function）来处理。常见的核函数有多项式核函数、径向基函数（RBF）核函数等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 非线性支持向量机（分类）\n",
    "nonlinear_svm = svm.SVC(kernel='rbf')  # 使用径向基函数核\n",
    "nonlinear_svm.fit(X2_train, y2_train)\n",
    "nonlinear_predictions = nonlinear_svm.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **支持向量回归（Support Vector Regression，SVR）：**\n",
    "\n",
    "与分类不同，SVR用于解决回归问题。它的目标是通过找到一个超平面，使得样本点在超平面上的投影与真实标签的差异最小化，同时允许一定的误差范围。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 支持向量回归\n",
    "svr = svm.SVR(kernel='linear')  # 使用线性核\n",
    "svr.fit(X1_train, y1_train)\n",
    "svr_predictions = svr.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **多类别支持向量机（Multiclass SVM）：** \n",
    "\n",
    "原始的SVM是用于二分类问题的，但可以通过一些方法扩展到多类别分类问题。常见的方法包括一对一（One-vs-One）和一对其余（One-vs-Rest）策略，其中前者在每一对类别之间训练一个分类器，后者在每个类别与其余所有类别之间训练一个分类器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 多类别支持向量机\n",
    "multiclass_svm = svm.SVC(kernel='linear', decision_function_shape='ovr')\n",
    "multiclass_svm.fit(X2_train, y2_train)\n",
    "multiclass_predictions = multiclass_svm.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **带约束的支持向量机（Constrained SVM）：**\n",
    "\n",
    "在一些应用中，可能需要加入额外的约束来引导SVM的训练过程，例如，对于异常检测或半监督学习等问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 带约束的支持向量机\n",
    "constrained_svm = svm.SVC(kernel='linear', C=10)  # 添加约束\n",
    "constrained_svm.fit(X2_train, y2_train)\n",
    "constrained_predictions = constrained_svm.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***决策树***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# For classification\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X2_train, y2_train)\n",
    "y_pred = clf.predict(X2_test)  # For classification\n",
    "\n",
    "# For regression\n",
    "reg = DecisionTreeRegressor(random_state=42)\n",
    "reg.fit(X1_train, y1_train)\n",
    "y_pred = reg.predict(X1_test)  # For regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
